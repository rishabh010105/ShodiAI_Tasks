```markdown
# ğŸ“˜ Policy Optimization for Financial Decision-Making (LendingClub)

This repository contains an end-to-end pipeline for:  
âœ” Exploratory Data Analysis (EDA)  
âœ” A supervised Deep Learning model for loan default prediction  
âœ” An Offline Reinforcement Learning (CQL) policy for loan approval decisions  
âœ” A full analytical comparison and recommendations report (Task 4)

The goal is to **maximize expected financial return** using the LendingClub accepted loan dataset.

---

## ğŸš€ 1. Project Structure
```

lendingclub-policy-optimization/
â”œâ”€ data/                         # dataset + preprocessed files
â”œâ”€ models/                       # trained models + scalers + RL policy
â”œâ”€ notebooks/                    # Jupyter notebooks for Tasks 1â€“4
â”œâ”€ requirements.txt
â””â”€ README.md

```

---

## ğŸ“¥ 2. Dataset Download

Download the LendingClub dataset from Kaggle:

ğŸ”— **https://www.kaggle.com/datasets/wordsforthewise/lending-club**

Place the file inside `data/`:

```

accepted_2007_to_2018Q4.csv.gz

````

(This file is NOT included in the repo due to size.)

---

## ğŸ›  3. Environment Setup

### âœ” Option A â€” Conda (Recommended)

```bash
conda create -n lendingclub-env python=3.10 -y
conda activate lendingclub-env
pip install -r requirements.txt
````

### âœ” Option B â€” venv / pip

```bash
python -m venv lendingclub-env
# Windows
.\lendingclub-env\Scripts\activate
# macOS/Linux
source lendingclub-env/bin/activate

pip install --upgrade pip
pip install -r requirements.txt
```

### requirements.txt (included)

```
numpy
pandas
scikit-learn
matplotlib
seaborn
joblib
torch
d3rlpy
jupyterlab
```

> The notebooks include compatibility code to handle different `d3rlpy` versions.

---

## â–¶ï¸ 4. Running the Project (Order Matters)

Start JupyterLab:

```bash
jupyter lab
```

Then run notebooks in this exact order:

---

### ğŸ“Œ 4.1 Task 1 â€” EDA & Preprocessing

Notebook: `notebooks/01_task1_EDA_preprocessing.ipynb`

This notebook:

* Loads raw CSV
* Performs EDA
* Cleans data
* Encodes categorical variables
* Saves:

Outputs (saved to `data/`):

* `df_encoded.joblib`
* `X_preprocessed.joblib`
* `y_preprocessed.joblib`

---

### ğŸ“Œ 4.2 Task 2 â€” Supervised Deep Learning Model

Notebook: `notebooks/02_task2_supervised_training.ipynb`

This notebook:

* Trains MLP classifier
* Computes AUC & F1
* Saves trained models

Outputs (saved to `models/`):

* `best_mlp.pth`
* `final_mlp.pth`
* `scaler.joblib`

---

### ğŸ“Œ 4.3 Task 3 â€” Offline RL (CQL Policy Learning)

Notebook: `notebooks/task3_offline_rl_&_TASK4.ipynb`

This notebook:

* Builds RL dataset
* Computes loan rewards
* Trains Conservative Q-Learning (CQL)
* Includes fallback compatibility code for older `d3rlpy` versions

Outputs (saved to `models/`):

* `cql_policy/`
* `policy_values_summary.joblib`

---

### ğŸ“Œ 4.4 Task 4 â€” Analysis & Final Report

Notebook: `notebooks/task3_offline_rl_&_TASK4.ipynb`

This notebook:

* Evaluates supervised vs RL policies
* Computes disagreement cases
* Produces final analysis & summary report

Outputs (saved to `models/`):

* `task4_analysis.md`
* Task 4 figures + CSVs
* Summary joblib files

---

## ğŸ§ª 5. Expected Results (Reference)

| Model                              | Value    |
| ---------------------------------- | -------- |
| **Supervised Model AUC**           | ~0.717   |
| **Supervised F1 (best threshold)** | ~0.434   |
| **Supervised Policy Value**        | âˆ’1395.72 |
| **RL Policy Value (CQL)**          | âˆ’1604.37 |
| **Approve-All Baseline**           | âˆ’1651.94 |
| **Deny-All Baseline**              | 0        |

---

## ğŸ†˜ 6. Troubleshooting

* **Cannot find CSV** â†’ Ensure `accepted_2007_to_2018Q4.csv.gz` is in `data/`.
* **d3rlpy errors** â†’ Run compatibility cell in Task 3.
* **MemoryError** â†’ Use sample-based scaler or reduce batch size.
* **Missing test_preds** â†’ Re-run Task 2 evaluation cells.


